{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff22f74-843e-461f-a6fa-35795276f3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Downloads'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d4eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c429d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas_datareader\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import os\n",
    "from pandas_datareader import data as pdr\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdecf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"KOSPI_200\")\n",
    "os.mkdir(\"KOSPI_200_OHLCV\") # directory 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f862fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = datetime.now() + timedelta(weeks=-52 * 1)\n",
    "table = pdr.get_data_yahoo('035720' + '.KS', start=start_dt).reset_index()['Date']\n",
    "todayYYMMDD = datetime.today().strftime(\"%Y%m%d\")\n",
    "table_today = table[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e69bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from functools import partial\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f7a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_load_ohlcv(kospi_value, f_data):\n",
    "    t_k = f_data[kospi_value + '.KS']\n",
    "    t_k['Date'] = t_k.index\n",
    "    new_col = t_k.columns[-1:].to_list() + t_k.columns[:-1].to_list()\n",
    "    t_k = t_k[new_col]\n",
    "    t_k = t_k.drop(['Adj Close'], axis=1)\n",
    "    t_k.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    t_k['Code'] = kospi_value\n",
    "    pd.DataFrame(t_k).to_csv('./KOSPI_200_OHLCV/' + kospi_value + '_OHLCV_' + todayYYMMDD + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4749906",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # KOSPI 200 종목 갱신 여부 (Default : N) 1년에 2회 갱신하지만 날짜가 고정되어 있지 않기 때문에 사용자가 직접 설정할 필요가 있음\n",
    "    load_kospi_list_yn = 'N'  # KOSPI 200 List Reloading Flag\n",
    "    load_kospi_ohlcv_yn_init = 'Y'  # KOSPI 200에 대한 ohlcv 정보를 처음부터 Reload Flag\n",
    "\n",
    "    if load_kospi_list_yn == 'Y':\n",
    "        # 종목코드 불러오기 (기업공시채널)\n",
    "        stock_code = pd.read_html('http://kind.krx.co.kr/corpgeneral/corpList.do?method=download', header=0)[0]\n",
    "        stock_code = stock_code[['회사명', '종목코드']]\n",
    "        # rename(columns = {'원래 이름' : '바꿀 이름'}) 칼럼 이름 바꾸기\n",
    "        stock_code = stock_code.rename(columns={'회사명': 'company', '종목코드': 'code'})\n",
    "        # 종목코드가 6자리이기 때문에 6자리를 맞춰주기 위해 설정해줌\n",
    "        stock_code.code = stock_code.code.map('{:06d}'.format)  # 6자리가 아닌 수를 앞에 0으로 채우기 위함\n",
    "        stock_code.tail(3)\n",
    "\n",
    "        # KOSPI 200 코드만 불러오기\n",
    "        import bs4\n",
    "        from urllib.request import urlopen  # url의 소스코드를 긁어오는 기능\n",
    "\n",
    "        # //*[@id=\"tab_con1\"]/div[3]/table/tbody/tr[1]/td/span[1]/em\n",
    "        company_name = []\n",
    "        for i in range(1, 21):\n",
    "            page = i\n",
    "            url = 'https://finance.naver.com/sise/entryJongmok.nhn?&page={page}'.format(page=page)\n",
    "            source = urlopen(url).read()\n",
    "            source = bs4.BeautifulSoup(source, 'lxml')\n",
    "            source = source.find_all('a', target='_parent')\n",
    "            for j in range(len(source)):\n",
    "                name = source[j].text\n",
    "                company_name.append(name)\n",
    "\n",
    "        code = []\n",
    "        for i in company_name:\n",
    "            for j in range(len(stock_code)):\n",
    "                if stock_code['company'][j] == i:\n",
    "                    code.append([stock_code['code'][j], stock_code['company'][j]])\n",
    "                    break\n",
    "\n",
    "        # 불러온 KOSPI 200 정보 CSV파일로 저장\n",
    "        hydf = pd.DataFrame(code)\n",
    "        hydf.columns = ['code', 'company']\n",
    "        hydf.to_csv('./KOSPI_200/kospi200_' + todayYYMMDD + '.csv', index=False)\n",
    "\n",
    "    # KOSPI 200 List LOADING (New)\n",
    "    dir = './KOSPI_200'\n",
    "    file = max(os.listdir(dir))\n",
    "    dir = dir + '/' + file\n",
    "    KOSPI_200_df = pd.read_csv(dir).iloc[:100, :]  # top 100개만 추출\n",
    "\n",
    "    start_dt = datetime.now() + timedelta(weeks=-52 * 1)\n",
    "\n",
    "    # KOSPI 200 종목에 대한 OHLCV정보 가져오기\n",
    "    kospi_200_ophcv = []\n",
    "    paralled_jobs = 6\n",
    "    yf.pdr_override()\n",
    "\n",
    "    import numpy as np\n",
    "    KOSPI_200_df['code'] = KOSPI_200_df['code'].map('{:06d}'.format)\n",
    "    KOSPI_200_df['code_ks'] = KOSPI_200_df['code'] + '.KS'\n",
    "    kospi_200_list = np.array(KOSPI_200_df['code']).tolist()\n",
    "\n",
    "    if load_kospi_ohlcv_yn_init == 'Y':\n",
    "        import time\n",
    "        import multiprocessing\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        # yfinance에서 Thread를 이용하여 Multi Stock Base Download를 제공하기 때문에 해당 기능 사용\n",
    "        kospi_200_list = np.array(KOSPI_200_df['code_ks']).tolist()\n",
    "        data = yf.download(\n",
    "            tickers=kospi_200_list,\n",
    "            threads=True,\n",
    "            group_by='ticker',\n",
    "            start=start_dt\n",
    "        )\n",
    "\n",
    "        # MultiProcessing\n",
    "        pool = multiprocessing.Pool(processes=paralled_jobs)  # process count setting\n",
    "        partial_func = partial(init_load_ohlcv, f_data=data)\n",
    "        pool.map(partial_func, [i for i in KOSPI_200_df['code'].values])\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        # No MultiProcessing\n",
    "        # for kospi_value in KOSPI_200_df['code']:\n",
    "        #     t_k = data[kospi_value + '.KS']\n",
    "        #     t_k['Date'] = t_k.index\n",
    "        #     new_col = t_k.columns[-1:].to_list() + t_k.columns[:-1].to_list()\n",
    "        #     t_k = t_k[new_col]\n",
    "        #     t_k = t_k.drop(['Adj Close'], axis=1)\n",
    "        #     t_k.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        #     t_k['Code'] = kospi_value\n",
    "        #     pd.DataFrame(t_k).to_csv('./KOSPI_200_OHLCV/' + kospi_value + '_OHLCV_' + todayYYMMDD + '.csv', index=False)\n",
    "\n",
    "        finish = time.perf_counter()\n",
    "        print(f'Finished in {round(finish - start, 2)} second(s)')\n",
    "\n",
    "    '''\n",
    "    else:\n",
    "        dir = './KOSPI_200_OHLCV'\n",
    "        file = max(os.listdir(dir))\n",
    "        dir = dir + '/' + file\n",
    "        KOSPI_200_OHLCV_df = pd.read_csv(dir)\n",
    "        table = KOSPI_200_OHLCV_df[pd.to_datetime(KOSPI_200_OHLCV_df['Date'], format = '%Y-%m-%d') >= start_dt]\n",
    "        table2 = pool.map(load_ohlcv, [i for i in KOSPI_200_df.values])\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        for i in table2:\n",
    "            table_today = pd.merge(table_today, i, how='left', on='Date')\n",
    "        print(table_today)\n",
    "        table_today['Date'] = table_today['Date'].apply(lambda x : datetime.strftime(x,\"%Y-%m-%d\"))\n",
    "        table = table[table['Date'] < datetime.today().strftime(\"%Y-%m-%d\")]\n",
    "        result_Table = pd.concat([table,table_today], ignore_index=True)\n",
    "        pd.DataFrame(result_Table).to_csv('./KOSPI_200_OHLCV/kospi200_OHLCV' + todayYYMMDD + '.csv', index=False)\n",
    "     '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb67256-6124-41ec-a1ca-1f533ea2ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 병합\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "input_file = 'KOSPI_200_OHLCV' # csv파일들이 있는 디렉토리 위치\n",
    "output_file = 'KOSPI_200_OHLCV/untitled.csv' # 병합하고 저장하려는 파일명\n",
    "\n",
    "allFile_list = glob.glob(os.path.join(input_file,'*.csv'))\n",
    "print(allFile_list)\n",
    "allData = [] # 읽어 들인 csv파일 내용을 저장할 빈 리스트를 하나 만든다\n",
    "for file in allFile_list:\n",
    "    df = pd.read_csv(file) # for구문으로 csv파일들을 읽어 들인다\n",
    "    allData.append(df) # 빈 리스트에 읽어 들인 내용을 추가한다\n",
    "dataCombine = pd.concat(allData, axis=0, ignore_index=True) # concat함수를 이용해서 리스트의 내용을 병합\n",
    "# axis=0은 수직으로 병합함. axis=1은 수평. ignore_index=True는 인데스 값이 기존 순서를 무시하고 순서대로 정렬되도록 한다.\n",
    "dataCombine.to_csv(output_file,index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afe67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64015887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c159ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "trd = pd.read_csv('KOSPI_200_OHLCV/trading_dataset.csv')\n",
    "trd['Date'] = pd.to_datetime(trd['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927aa0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import date, timedelta\n",
    "\n",
    "today = date.today()\n",
    "sell_date = pd.date_range(start='2022-01-01', end='today', freq='W-FRI')\n",
    "buy_date = pd.date_range(start='2022-01-01', end='today', freq='W-MON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7719f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_pick(c):\n",
    "    start_date = buy_date[c] - timedelta(weeks=1)\n",
    "    end_date = sell_date[c] - timedelta(weeks=1)\n",
    "    trd_stock = trd[(trd['Date'] >= start_date) & (trd['Date'] <= end_date)]\n",
    "    days = trd_stock.groupby('Code').count()['Date'].iloc[0]\n",
    "    \n",
    "    if (days == 5):\n",
    "        trdd = trd[(trd['Date'] >= start_date) & (trd['Date'] <= end_date)]\n",
    "        trd1 = trdd[['Close', 'Volume', 'Code']].groupby('Code').diff().diff().rename(columns = {'Close' : 'diff_Close' , 'Volume' : 'diff_Volume'})\n",
    "        trd2 = trd1.diff().diff().sort_values(by = 'diff_Close', ascending = False)\n",
    "        trd2 = pd.concat([trdd,trd2],axis=1)\n",
    "        trd3 = trd2.sort_values(by = 'diff_Close', ascending = False).head(10)\n",
    "        trd4 = trd3.sort_values(by = 'diff_Volume', ascending = False).head(1)\n",
    "        df_stock = int(trd4['Code'])\n",
    "  \n",
    "    elif (days == 4):\n",
    "        trdd = trd[(trd['Date'] >= start_date) & (trd['Date'] <= end_date)]\n",
    "        trd1 = trdd[['Close', 'Volume', 'Code']].groupby('Code').diff().diff().rename(columns = {'Close' : 'diff_Close' , 'Volume' : 'diff_Volume'})\n",
    "        trd2 = trd1.diff().sort_values(by = 'diff_Close', ascending = False)\n",
    "        trd2 = pd.concat([trdd,trd2],axis=1)\n",
    "        trd3 = trd2.sort_values(by = 'diff_Close', ascending = False).head(10)\n",
    "        trd4 = trd3.sort_values(by = 'diff_Volume', ascending = False).head(1)\n",
    "        df_stock = int(trd4['Code'])\n",
    "        \n",
    "    else:\n",
    "        df_stock = None\n",
    "        \n",
    "    return df_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7814108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade(z): \n",
    "     \n",
    "    bank = 10000000\n",
    "    trd_stock = trd[(trd['Date'] >= buy_date[z]) & (trd['Date'] <= sell_date[z])]\n",
    "    days = trd_stock.groupby('Code').count()['Date'].iloc[0]\n",
    "    \n",
    "    if stock_pick(z) != None:\n",
    "        trd_week = trd_stock[trd_stock['Code'] == stock_pick(z)]\n",
    "        stock_code = stock_pick(z)\n",
    "        buy_stock_price = trd_week.iloc[0]['Open']\n",
    "        hold_stock = bank // buy_stock_price\n",
    "        sell_stock_price = trd_week.iloc[days-1]['Close']\n",
    "        profit = (sell_stock_price - buy_stock_price) * hold_stock\n",
    "        return { 'stock_code' : stock_code ,\n",
    "                 'buy_stock_price' : buy_stock_price,\n",
    "                 'hold_stock' : hold_stock,\n",
    "                 'sell_stock_price' : sell_stock_price,\n",
    "                 'profit' : profit }\n",
    "    \n",
    "    else:\n",
    "        return { 'stock_code' : None ,\n",
    "                 'buy_stock_price' : None,\n",
    "                 'hold_stock' : None,\n",
    "                 'sell_stock_price' : None,\n",
    "                 'profit' : 0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb9c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(i):\n",
    "        \n",
    "    if trade(i)['stock_code'] != None:\n",
    "        print('week : ' + str(i))\n",
    "        print('stock_code : %06d'  %trade(i)['stock_code'])\n",
    "        print('buy_stock_price : %.f' %trade(i)['buy_stock_price'])\n",
    "        print('hold_stock :' , trade(i)['hold_stock'])\n",
    "        print('sell_stock_price :' , trade(i)['sell_stock_price'])\n",
    "        print('profit :' , trade(i)['profit'])\n",
    "        print(' ')\n",
    "\n",
    "    else:\n",
    "        print('week : ' + str(i))\n",
    "        print('No trade')\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bff094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play():\n",
    "    total_profit = 0\n",
    "    for i in range(32):\n",
    "        trade(i)\n",
    "        summary(i)\n",
    "        total_profit += trade(i)['profit']\n",
    "    print(total_profit)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470a80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
